{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: EOG Signal Analysis and Gaze Classification\n",
    "\n",
    "**BioRobotics - Introduction to Electrooculography**\n",
    "\n",
    "This notebook guides you through the analysis of EOG (electrooculography) data collected with the BioRadio device. You will:\n",
    "\n",
    "1. **Load and visualize** raw EOG signals\n",
    "2. **Process signals** with baseline correction and filtering\n",
    "3. **Detect blink artifacts** in the data\n",
    "4. **Extract features** for classification\n",
    "5. **Apply dimensionality reduction** using PCA and ICA\n",
    "6. **Classify gaze directions** using SVM (Linear and RBF kernels)\n",
    "7. **Evaluate performance** with confusion matrices and metrics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Signal processing\n",
    "from scipy import signal\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, accuracy_score,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your data directory and recording parameters below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION - EDIT THESE ===\n",
    "\n",
    "# Path to your recorded data folder\n",
    "DATA_DIR = Path(\"../data\")  # Adjust this to your data location\n",
    "\n",
    "# Recording parameters\n",
    "SAMPLE_RATE = 250  # Hz (should match your BioRadio configuration)\n",
    "\n",
    "# Channel mapping\n",
    "HEOG_CHANNEL = 0  # Horizontal EOG (Channel 1 on BioRadio)\n",
    "VEOG_CHANNEL = 1  # Vertical EOG (Channel 2 on BioRadio)\n",
    "\n",
    "# Gaze classes to analyze\n",
    "GAZE_CLASSES = ['center', 'left', 'right', 'up', 'down', 'blink', 'double_blink']\n",
    "\n",
    "# Filter parameters\n",
    "LOWPASS_CUTOFF = 30  # Hz - EOG content is below 30 Hz\n",
    "HIGHPASS_CUTOFF = 0.1  # Hz - removes very slow drift (optional)\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR.absolute()}\")\n",
    "print(f\"Sample rate: {SAMPLE_RATE} Hz\")\n",
    "print(f\"Gaze classes: {GAZE_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Loading and Exploring the Data\n",
    "\n",
    "First, let's discover what data files are available and load them into a structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_data_files(data_dir, pattern=\"*.csv\"):\n",
    "    \"\"\"\n",
    "    Find all CSV files in the data directory and extract metadata from filenames.\n",
    "    \n",
    "    Expected filename format: {participant}_{gaze}_{trial}_{timestamp}.csv\n",
    "    Example: P01_left_trial003_20250206_143022.csv\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    files = []\n",
    "    \n",
    "    # Search recursively\n",
    "    for csv_file in data_dir.rglob(pattern):\n",
    "        filename = csv_file.stem\n",
    "        \n",
    "        # Try to parse the filename\n",
    "        # Pattern: participant_gaze_trial###_timestamp\n",
    "        parts = filename.split('_')\n",
    "        \n",
    "        if len(parts) >= 3:\n",
    "            participant = parts[0]\n",
    "            gaze = parts[1]\n",
    "            \n",
    "            # Extract trial number\n",
    "            trial_match = re.search(r'trial(\\d+)', filename, re.IGNORECASE)\n",
    "            trial = int(trial_match.group(1)) if trial_match else 0\n",
    "            \n",
    "            files.append({\n",
    "                'path': csv_file,\n",
    "                'participant': participant,\n",
    "                'gaze': gaze.lower(),\n",
    "                'trial': trial,\n",
    "                'filename': filename\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(files)\n",
    "\n",
    "# Find all data files\n",
    "file_df = find_data_files(DATA_DIR)\n",
    "\n",
    "if len(file_df) == 0:\n",
    "    print(\"⚠️ No data files found!\")\n",
    "    print(f\"   Searched in: {DATA_DIR.absolute()}\")\n",
    "    print(\"   Make sure your data files are in the correct location.\")\n",
    "else:\n",
    "    print(f\"Found {len(file_df)} data files\\n\")\n",
    "    \n",
    "    # Summary by gaze class\n",
    "    print(\"Trials per gaze class:\")\n",
    "    print(file_df.groupby('gaze').size().to_string())\n",
    "    print()\n",
    "    \n",
    "    # Summary by participant\n",
    "    print(\"\\nTrials per participant:\")\n",
    "    print(file_df.groupby('participant').size().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eog_file(filepath):\n",
    "    \"\"\"\n",
    "    Load a single EOG data file.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: timestamp, heog, veog (and any other channels)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Standardize column names\n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "    \n",
    "    # If columns are numbered (ch0, ch1, etc.), rename them\n",
    "    if 'ch0' in df.columns or 'channel_0' in df.columns:\n",
    "        rename_map = {\n",
    "            'ch0': 'heog', 'channel_0': 'heog',\n",
    "            'ch1': 'veog', 'channel_1': 'veog',\n",
    "        }\n",
    "        df = df.rename(columns=rename_map)\n",
    "    \n",
    "    # If no timestamp column, create one based on sample rate\n",
    "    if 'timestamp' not in df.columns and 'time' not in df.columns:\n",
    "        df['timestamp'] = np.arange(len(df)) / SAMPLE_RATE\n",
    "    elif 'time' in df.columns:\n",
    "        df = df.rename(columns={'time': 'timestamp'})\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load a sample file to inspect the structure\n",
    "if len(file_df) > 0:\n",
    "    sample_file = file_df.iloc[0]['path']\n",
    "    sample_data = load_eog_file(sample_file)\n",
    "    \n",
    "    print(f\"Sample file: {sample_file.name}\")\n",
    "    print(f\"Shape: {sample_data.shape}\")\n",
    "    print(f\"Columns: {list(sample_data.columns)}\")\n",
    "    print(f\"Duration: {len(sample_data) / SAMPLE_RATE:.2f} seconds\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    display(sample_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_trials(file_df, gaze_classes=None):\n",
    "    \"\"\"\n",
    "    Load all trials into a structured dictionary.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {gaze_class: [list of DataFrames]}\n",
    "    \"\"\"\n",
    "    if gaze_classes is None:\n",
    "        gaze_classes = file_df['gaze'].unique()\n",
    "    \n",
    "    all_data = {gaze: [] for gaze in gaze_classes}\n",
    "    \n",
    "    for _, row in file_df.iterrows():\n",
    "        gaze = row['gaze']\n",
    "        if gaze in gaze_classes:\n",
    "            try:\n",
    "                df = load_eog_file(row['path'])\n",
    "                df['participant'] = row['participant']\n",
    "                df['trial'] = row['trial']\n",
    "                df['gaze'] = gaze\n",
    "                all_data[gaze].append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {row['path']}: {e}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"Loaded trials per class:\")\n",
    "    for gaze, trials in all_data.items():\n",
    "        if trials:\n",
    "            total_samples = sum(len(t) for t in trials)\n",
    "            print(f\"  {gaze}: {len(trials)} trials, {total_samples} samples\")\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "# Load all data\n",
    "if len(file_df) > 0:\n",
    "    all_data = load_all_trials(file_df, GAZE_CLASSES)\n",
    "else:\n",
    "    print(\"No data to load. Using synthetic data for demonstration...\")\n",
    "    all_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Raw EOG Signals\n",
    "\n",
    "Let's look at example signals for each gaze direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raw_eog(data_dict, num_examples=1):\n",
    "    \"\"\"\n",
    "    Plot raw EOG signals for each gaze class.\n",
    "    \"\"\"\n",
    "    gaze_classes = [g for g in data_dict.keys() if data_dict[g]]\n",
    "    n_classes = len(gaze_classes)\n",
    "    \n",
    "    if n_classes == 0:\n",
    "        print(\"No data to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(n_classes, 2, figsize=(14, 3 * n_classes))\n",
    "    if n_classes == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, gaze in enumerate(gaze_classes):\n",
    "        trials = data_dict[gaze]\n",
    "        if not trials:\n",
    "            continue\n",
    "            \n",
    "        # Plot first trial\n",
    "        trial = trials[0]\n",
    "        time = np.arange(len(trial)) / SAMPLE_RATE\n",
    "        \n",
    "        # HEOG\n",
    "        ax1 = axes[i, 0]\n",
    "        if 'heog' in trial.columns:\n",
    "            ax1.plot(time, trial['heog'], 'b-', linewidth=0.8)\n",
    "        ax1.set_ylabel('HEOG (μV)')\n",
    "        ax1.set_title(f'{gaze.upper()} - Horizontal EOG')\n",
    "        ax1.set_xlabel('Time (s)')\n",
    "        \n",
    "        # VEOG\n",
    "        ax2 = axes[i, 1]\n",
    "        if 'veog' in trial.columns:\n",
    "            ax2.plot(time, trial['veog'], 'r-', linewidth=0.8)\n",
    "        ax2.set_ylabel('VEOG (μV)')\n",
    "        ax2.set_title(f'{gaze.upper()} - Vertical EOG')\n",
    "        ax2.set_xlabel('Time (s)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if all_data:\n",
    "    plot_raw_eog(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 1 Response\n",
    "\n",
    "**Sketch the EOG waveforms you observe for each gaze direction. Which channel responds to which movement?**\n",
    "\n",
    "*Your observations:*\n",
    "\n",
    "- **Left gaze:** HEOG shows ___ deflection, VEOG shows ___\n",
    "- **Right gaze:** HEOG shows ___ deflection, VEOG shows ___\n",
    "- **Up gaze:** HEOG shows ___, VEOG shows ___ deflection\n",
    "- **Down gaze:** HEOG shows ___, VEOG shows ___ deflection\n",
    "- **Center:** Both channels show ___\n",
    "- **Approximate amplitude:** ___ μV per gaze direction\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Signal Processing\n",
    "\n",
    "EOG signals require specific processing to remove artifacts and prepare for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_correction(signal_data, method='mean'):\n",
    "    \"\"\"\n",
    "    Remove DC offset from the signal.\n",
    "    \n",
    "    Args:\n",
    "        signal_data: 1D array of signal values\n",
    "        method: 'mean' (subtract mean) or 'median' (subtract median)\n",
    "        \n",
    "    Returns:\n",
    "        Baseline-corrected signal\n",
    "    \"\"\"\n",
    "    if method == 'mean':\n",
    "        return signal_data - np.mean(signal_data)\n",
    "    elif method == 'median':\n",
    "        return signal_data - np.median(signal_data)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "\n",
    "def remove_drift(signal_data, window_size=None, sample_rate=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    Remove slow baseline drift using a moving average subtraction.\n",
    "    \n",
    "    Args:\n",
    "        signal_data: 1D array of signal values\n",
    "        window_size: Size of moving average window in samples\n",
    "                     Default is 2 seconds worth of samples\n",
    "    \n",
    "    Returns:\n",
    "        Drift-corrected signal\n",
    "    \"\"\"\n",
    "    if window_size is None:\n",
    "        window_size = int(2 * sample_rate)  # 2 second window\n",
    "    \n",
    "    # Compute moving average (baseline estimate)\n",
    "    baseline = uniform_filter1d(signal_data, size=window_size, mode='nearest')\n",
    "    \n",
    "    return signal_data - baseline\n",
    "\n",
    "\n",
    "def lowpass_filter(signal_data, cutoff=LOWPASS_CUTOFF, sample_rate=SAMPLE_RATE, order=4):\n",
    "    \"\"\"\n",
    "    Apply a low-pass Butterworth filter.\n",
    "    \n",
    "    Args:\n",
    "        signal_data: 1D array of signal values\n",
    "        cutoff: Cutoff frequency in Hz\n",
    "        sample_rate: Sampling rate in Hz\n",
    "        order: Filter order\n",
    "        \n",
    "    Returns:\n",
    "        Filtered signal\n",
    "    \"\"\"\n",
    "    nyquist = sample_rate / 2\n",
    "    normalized_cutoff = cutoff / nyquist\n",
    "    \n",
    "    b, a = signal.butter(order, normalized_cutoff, btype='low')\n",
    "    \n",
    "    # Use filtfilt for zero-phase filtering\n",
    "    return signal.filtfilt(b, a, signal_data)\n",
    "\n",
    "\n",
    "def bandpass_filter(signal_data, low_cutoff=HIGHPASS_CUTOFF, high_cutoff=LOWPASS_CUTOFF,\n",
    "                    sample_rate=SAMPLE_RATE, order=4):\n",
    "    \"\"\"\n",
    "    Apply a band-pass Butterworth filter.\n",
    "    \n",
    "    Args:\n",
    "        signal_data: 1D array of signal values\n",
    "        low_cutoff: Low cutoff frequency in Hz\n",
    "        high_cutoff: High cutoff frequency in Hz\n",
    "        \n",
    "    Returns:\n",
    "        Filtered signal\n",
    "    \"\"\"\n",
    "    nyquist = sample_rate / 2\n",
    "    low = low_cutoff / nyquist\n",
    "    high = high_cutoff / nyquist\n",
    "    \n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    \n",
    "    return signal.filtfilt(b, a, signal_data)\n",
    "\n",
    "\n",
    "def process_eog_signal(signal_data, sample_rate=SAMPLE_RATE,\n",
    "                       remove_baseline=True, remove_slow_drift=False,\n",
    "                       apply_lowpass=True, lowpass_cutoff=LOWPASS_CUTOFF):\n",
    "    \"\"\"\n",
    "    Full processing pipeline for EOG signals.\n",
    "    \n",
    "    Args:\n",
    "        signal_data: 1D array of signal values\n",
    "        sample_rate: Sampling rate in Hz\n",
    "        remove_baseline: Subtract mean from signal\n",
    "        remove_slow_drift: Apply drift removal (moving average subtraction)\n",
    "        apply_lowpass: Apply low-pass filter\n",
    "        lowpass_cutoff: Cutoff frequency for low-pass filter\n",
    "        \n",
    "    Returns:\n",
    "        Processed signal\n",
    "    \"\"\"\n",
    "    processed = signal_data.copy()\n",
    "    \n",
    "    # Step 1: Baseline correction\n",
    "    if remove_baseline:\n",
    "        processed = baseline_correction(processed, method='mean')\n",
    "    \n",
    "    # Step 2: Remove slow drift (optional)\n",
    "    if remove_slow_drift:\n",
    "        processed = remove_drift(processed, sample_rate=sample_rate)\n",
    "    \n",
    "    # Step 3: Low-pass filter\n",
    "    if apply_lowpass:\n",
    "        processed = lowpass_filter(processed, cutoff=lowpass_cutoff,\n",
    "                                   sample_rate=sample_rate)\n",
    "    \n",
    "    return processed\n",
    "\n",
    "print(\"Signal processing functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Raw vs. Processed Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_processing_comparison(trial_data, sample_rate=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    Show the effect of signal processing on a single trial.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "    time = np.arange(len(trial_data)) / sample_rate\n",
    "    \n",
    "    channels = [('heog', 'HEOG', 'blue'), ('veog', 'VEOG', 'red')]\n",
    "    \n",
    "    for col, (ch_name, ch_label, color) in enumerate(channels):\n",
    "        if ch_name not in trial_data.columns:\n",
    "            continue\n",
    "            \n",
    "        raw = trial_data[ch_name].values\n",
    "        processed = process_eog_signal(raw, sample_rate=sample_rate)\n",
    "        \n",
    "        # Raw signal\n",
    "        axes[0, col].plot(time, raw, color=color, linewidth=0.8, alpha=0.8)\n",
    "        axes[0, col].set_title(f'{ch_label} - Raw Signal')\n",
    "        axes[0, col].set_xlabel('Time (s)')\n",
    "        axes[0, col].set_ylabel('Amplitude (μV)')\n",
    "        \n",
    "        # Processed signal\n",
    "        axes[1, col].plot(time, processed, color=color, linewidth=0.8, alpha=0.8)\n",
    "        axes[1, col].set_title(f'{ch_label} - Processed (baseline corrected + low-pass filtered)')\n",
    "        axes[1, col].set_xlabel('Time (s)')\n",
    "        axes[1, col].set_ylabel('Amplitude (μV)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot comparison for one trial\n",
    "if all_data:\n",
    "    # Find a gaze class with data\n",
    "    for gaze in ['left', 'right', 'center']:\n",
    "        if gaze in all_data and all_data[gaze]:\n",
    "            print(f\"Processing example from '{gaze}' class:\")\n",
    "            plot_processing_comparison(all_data[gaze][0])\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 5 Response\n",
    "\n",
    "**Compare the raw and filtered EOG signals. What types of noise does the low-pass filter remove? How does baseline correction affect the signal?**\n",
    "\n",
    "*Your observations:*\n",
    "\n",
    "- The low-pass filter removes: ___\n",
    "- Baseline correction affects the signal by: ___\n",
    "- The processed signal is better for classification because: ___\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Blink Detection\n",
    "\n",
    "Blinks create large, characteristic artifacts in the VEOG channel. We can detect them for removal or use them as a control signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_blinks(veog_signal, sample_rate=SAMPLE_RATE,\n",
    "                  threshold_factor=3.0, min_duration_ms=50, max_duration_ms=400):\n",
    "    \"\"\"\n",
    "    Detect blinks in the VEOG signal using threshold crossing.\n",
    "    \n",
    "    Blinks appear as large, sharp positive deflections in VEOG.\n",
    "    \n",
    "    Args:\n",
    "        veog_signal: 1D array of VEOG values\n",
    "        sample_rate: Sampling rate in Hz\n",
    "        threshold_factor: Multiple of std dev to use as threshold\n",
    "        min_duration_ms: Minimum blink duration in milliseconds\n",
    "        max_duration_ms: Maximum blink duration in milliseconds\n",
    "        \n",
    "    Returns:\n",
    "        list of tuples: [(start_sample, end_sample, peak_sample), ...]\n",
    "    \"\"\"\n",
    "    # Process signal\n",
    "    processed = baseline_correction(veog_signal)\n",
    "    \n",
    "    # Calculate threshold\n",
    "    std = np.std(processed)\n",
    "    threshold = threshold_factor * std\n",
    "    \n",
    "    # Find samples above threshold\n",
    "    above_threshold = processed > threshold\n",
    "    \n",
    "    # Find blink regions\n",
    "    blinks = []\n",
    "    min_samples = int(min_duration_ms * sample_rate / 1000)\n",
    "    max_samples = int(max_duration_ms * sample_rate / 1000)\n",
    "    \n",
    "    in_blink = False\n",
    "    blink_start = 0\n",
    "    \n",
    "    for i, above in enumerate(above_threshold):\n",
    "        if above and not in_blink:\n",
    "            # Start of potential blink\n",
    "            in_blink = True\n",
    "            blink_start = i\n",
    "        elif not above and in_blink:\n",
    "            # End of potential blink\n",
    "            in_blink = False\n",
    "            blink_end = i\n",
    "            duration = blink_end - blink_start\n",
    "            \n",
    "            # Check duration criteria\n",
    "            if min_samples <= duration <= max_samples:\n",
    "                # Find peak within blink region\n",
    "                peak_idx = blink_start + np.argmax(processed[blink_start:blink_end])\n",
    "                blinks.append((blink_start, blink_end, peak_idx))\n",
    "    \n",
    "    return blinks\n",
    "\n",
    "\n",
    "def plot_blink_detection(trial_data, sample_rate=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    Visualize blink detection on VEOG signal.\n",
    "    \"\"\"\n",
    "    if 'veog' not in trial_data.columns:\n",
    "        print(\"No VEOG channel found\")\n",
    "        return\n",
    "    \n",
    "    veog = trial_data['veog'].values\n",
    "    time = np.arange(len(veog)) / sample_rate\n",
    "    \n",
    "    # Detect blinks\n",
    "    blinks = detect_blinks(veog, sample_rate=sample_rate)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 4))\n",
    "    ax.plot(time, veog, 'b-', linewidth=0.8, label='VEOG')\n",
    "    \n",
    "    # Mark detected blinks\n",
    "    for start, end, peak in blinks:\n",
    "        ax.axvspan(start/sample_rate, end/sample_rate, \n",
    "                   color='red', alpha=0.3, label='Blink' if start == blinks[0][0] else '')\n",
    "        ax.plot(peak/sample_rate, veog[peak], 'r^', markersize=10)\n",
    "    \n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('VEOG (μV)')\n",
    "    ax.set_title(f'Blink Detection - Found {len(blinks)} blink(s)')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return blinks\n",
    "\n",
    "# Test blink detection on blink trials\n",
    "if all_data and 'blink' in all_data and all_data['blink']:\n",
    "    print(\"Blink detection on 'blink' class trial:\")\n",
    "    detected = plot_blink_detection(all_data['blink'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 2 Response\n",
    "\n",
    "**How do blink artifacts appear in the HEOG vs. VEOG channels? Why might blinks primarily affect the VEOG channel?**\n",
    "\n",
    "*Your observations:*\n",
    "\n",
    "- In the VEOG channel, blinks appear as: ___\n",
    "- In the HEOG channel, blinks appear as: ___\n",
    "- Blinks primarily affect VEOG because: ___\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Feature Extraction\n",
    "\n",
    "Extract features from each trial for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(trial_data, sample_rate=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    Extract features from a single EOG trial.\n",
    "    \n",
    "    Features extracted:\n",
    "    - Mean amplitude (HEOG, VEOG)\n",
    "    - Standard deviation (HEOG, VEOG)\n",
    "    - Peak-to-peak amplitude (HEOG, VEOG)\n",
    "    - RMS (Root Mean Square) (HEOG, VEOG)\n",
    "    - Max absolute value (HEOG, VEOG)\n",
    "    - Signal range (HEOG, VEOG)\n",
    "    - Zero crossings (HEOG, VEOG)\n",
    "    - Energy (sum of squared values)\n",
    "    \n",
    "    Returns:\n",
    "        dict of features\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    for ch_name in ['heog', 'veog']:\n",
    "        if ch_name not in trial_data.columns:\n",
    "            continue\n",
    "        \n",
    "        # Get raw and processed signals\n",
    "        raw = trial_data[ch_name].values\n",
    "        processed = process_eog_signal(raw, sample_rate=sample_rate)\n",
    "        \n",
    "        prefix = ch_name.upper()\n",
    "        \n",
    "        # Time-domain features on processed signal\n",
    "        features[f'{prefix}_mean'] = np.mean(processed)\n",
    "        features[f'{prefix}_std'] = np.std(processed)\n",
    "        features[f'{prefix}_min'] = np.min(processed)\n",
    "        features[f'{prefix}_max'] = np.max(processed)\n",
    "        features[f'{prefix}_ptp'] = np.ptp(processed)  # peak-to-peak\n",
    "        features[f'{prefix}_rms'] = np.sqrt(np.mean(processed**2))\n",
    "        features[f'{prefix}_abs_max'] = np.max(np.abs(processed))\n",
    "        features[f'{prefix}_energy'] = np.sum(processed**2)\n",
    "        \n",
    "        # Zero crossings (indicates oscillation)\n",
    "        zero_crossings = np.sum(np.diff(np.sign(processed)) != 0)\n",
    "        features[f'{prefix}_zero_crossings'] = zero_crossings\n",
    "        \n",
    "        # Skewness and kurtosis\n",
    "        from scipy.stats import skew, kurtosis\n",
    "        features[f'{prefix}_skew'] = skew(processed)\n",
    "        features[f'{prefix}_kurtosis'] = kurtosis(processed)\n",
    "        \n",
    "        # Derivative features (velocity)\n",
    "        velocity = np.diff(processed) * sample_rate\n",
    "        features[f'{prefix}_velocity_max'] = np.max(np.abs(velocity))\n",
    "        features[f'{prefix}_velocity_std'] = np.std(velocity)\n",
    "    \n",
    "    # Combined features\n",
    "    if 'heog' in trial_data.columns and 'veog' in trial_data.columns:\n",
    "        heog = process_eog_signal(trial_data['heog'].values)\n",
    "        veog = process_eog_signal(trial_data['veog'].values)\n",
    "        \n",
    "        # Ratio features\n",
    "        heog_energy = np.sum(heog**2)\n",
    "        veog_energy = np.sum(veog**2)\n",
    "        total_energy = heog_energy + veog_energy\n",
    "        \n",
    "        if total_energy > 0:\n",
    "            features['HEOG_energy_ratio'] = heog_energy / total_energy\n",
    "            features['VEOG_energy_ratio'] = veog_energy / total_energy\n",
    "        \n",
    "        # Correlation between channels\n",
    "        features['channel_correlation'] = np.corrcoef(heog, veog)[0, 1]\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_all_features(data_dict, sample_rate=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    Extract features from all trials in the dataset.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with features and labels\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    \n",
    "    for gaze_class, trials in data_dict.items():\n",
    "        for i, trial in enumerate(trials):\n",
    "            try:\n",
    "                features = extract_features(trial, sample_rate=sample_rate)\n",
    "                features['gaze'] = gaze_class\n",
    "                features['trial'] = i\n",
    "                if 'participant' in trial.columns:\n",
    "                    features['participant'] = trial['participant'].iloc[0]\n",
    "                all_features.append(features)\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting features from {gaze_class} trial {i}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(all_features)\n",
    "\n",
    "# Extract features from all data\n",
    "if all_data:\n",
    "    feature_df = extract_all_features(all_data)\n",
    "    print(f\"Extracted features from {len(feature_df)} trials\")\n",
    "    print(f\"Number of features: {len([c for c in feature_df.columns if c not in ['gaze', 'trial', 'participant']])}\")\n",
    "    print(\"\\nFeature summary:\")\n",
    "    display(feature_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_distributions(feature_df, features_to_plot=None):\n",
    "    \"\"\"\n",
    "    Plot distributions of key features by gaze class.\n",
    "    \"\"\"\n",
    "    if features_to_plot is None:\n",
    "        features_to_plot = ['HEOG_mean', 'VEOG_mean', 'HEOG_std', 'VEOG_std']\n",
    "    \n",
    "    # Filter to features that exist\n",
    "    features_to_plot = [f for f in features_to_plot if f in feature_df.columns]\n",
    "    \n",
    "    if not features_to_plot:\n",
    "        print(\"No features to plot\")\n",
    "        return\n",
    "    \n",
    "    n_features = len(features_to_plot)\n",
    "    fig, axes = plt.subplots(1, n_features, figsize=(4 * n_features, 4))\n",
    "    if n_features == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    gaze_classes = feature_df['gaze'].unique()\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(gaze_classes)))\n",
    "    \n",
    "    for ax, feature in zip(axes, features_to_plot):\n",
    "        for gaze, color in zip(gaze_classes, colors):\n",
    "            data = feature_df[feature_df['gaze'] == gaze][feature]\n",
    "            ax.hist(data, bins=15, alpha=0.5, label=gaze, color=color)\n",
    "        \n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if all_data and 'feature_df' in dir():\n",
    "    plot_feature_distributions(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_scatter(feature_df, x_feature='HEOG_mean', y_feature='VEOG_mean'):\n",
    "    \"\"\"\n",
    "    Create a scatter plot of two features colored by gaze class.\n",
    "    \"\"\"\n",
    "    if x_feature not in feature_df.columns or y_feature not in feature_df.columns:\n",
    "        print(f\"Features not found. Available: {list(feature_df.columns)}\")\n",
    "        return\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    gaze_classes = feature_df['gaze'].unique()\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(gaze_classes)))\n",
    "    \n",
    "    for gaze, color in zip(gaze_classes, colors):\n",
    "        mask = feature_df['gaze'] == gaze\n",
    "        ax.scatter(feature_df[mask][x_feature], \n",
    "                   feature_df[mask][y_feature],\n",
    "                   c=[color], label=gaze, s=60, alpha=0.7, edgecolors='white')\n",
    "    \n",
    "    ax.set_xlabel(x_feature)\n",
    "    ax.set_ylabel(y_feature)\n",
    "    ax.set_title(f'{x_feature} vs {y_feature} by Gaze Class')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if all_data and 'feature_df' in dir():\n",
    "    plot_feature_scatter(feature_df, 'HEOG_mean', 'VEOG_mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 6 Response\n",
    "\n",
    "**Which features show the most separation between different gaze directions?**\n",
    "\n",
    "*Your observations:*\n",
    "\n",
    "- Features that separate horizontal gaze (left/right): ___\n",
    "- Features that separate vertical gaze (up/down): ___\n",
    "- Features that identify blinks: ___\n",
    "- The most discriminative feature overall is: ___\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Dimensionality Reduction\n",
    "\n",
    "### 5.1 Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(feature_df, n_components=2):\n",
    "    \"\"\"\n",
    "    Apply PCA to the feature matrix.\n",
    "    \n",
    "    Returns:\n",
    "        pca: fitted PCA object\n",
    "        X_pca: transformed data\n",
    "        feature_names: list of feature names used\n",
    "    \"\"\"\n",
    "    # Get numeric features only\n",
    "    exclude_cols = ['gaze', 'trial', 'participant']\n",
    "    feature_cols = [c for c in feature_df.columns if c not in exclude_cols]\n",
    "    \n",
    "    X = feature_df[feature_cols].values\n",
    "    \n",
    "    # Handle missing values\n",
    "    X = np.nan_to_num(X, nan=0)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    return pca, X_pca, feature_cols\n",
    "\n",
    "\n",
    "def plot_pca_results(feature_df, pca, X_pca):\n",
    "    \"\"\"\n",
    "    Visualize PCA results.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Scatter plot in PC space\n",
    "    ax1 = axes[0]\n",
    "    gaze_classes = feature_df['gaze'].unique()\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(gaze_classes)))\n",
    "    \n",
    "    for gaze, color in zip(gaze_classes, colors):\n",
    "        mask = feature_df['gaze'] == gaze\n",
    "        ax1.scatter(X_pca[mask, 0], X_pca[mask, 1],\n",
    "                    c=[color], label=gaze, s=60, alpha=0.7, edgecolors='white')\n",
    "    \n",
    "    ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
    "    ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
    "    ax1.set_title('PCA: Gaze Classes in PC Space')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Explained variance\n",
    "    ax2 = axes[1]\n",
    "    cumulative_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "    ax2.bar(range(1, len(pca.explained_variance_ratio_) + 1),\n",
    "            pca.explained_variance_ratio_, alpha=0.7, label='Individual')\n",
    "    ax2.plot(range(1, len(cumulative_var) + 1), cumulative_var,\n",
    "             'ro-', label='Cumulative')\n",
    "    ax2.set_xlabel('Principal Component')\n",
    "    ax2.set_ylabel('Explained Variance Ratio')\n",
    "    ax2.set_title('PCA: Explained Variance')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print variance explained\n",
    "    print(\"\\nVariance explained by each component:\")\n",
    "    for i, var in enumerate(pca.explained_variance_ratio_):\n",
    "        print(f\"  PC{i+1}: {var*100:.2f}%\")\n",
    "    print(f\"  Total (first 2): {sum(pca.explained_variance_ratio_[:2])*100:.2f}%\")\n",
    "\n",
    "# Apply PCA\n",
    "if all_data and 'feature_df' in dir() and len(feature_df) > 0:\n",
    "    pca, X_pca, feature_names = apply_pca(feature_df, n_components=min(10, len(feature_df)))\n",
    "    plot_pca_results(feature_df, pca, X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Independent Component Analysis (ICA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ica_to_signals(trial_data, n_components=2, sample_rate=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    Apply ICA directly to the raw EOG signals to separate sources.\n",
    "    \n",
    "    This can help separate eye movement signals from blink artifacts.\n",
    "    \n",
    "    Returns:\n",
    "        ica: fitted ICA object\n",
    "        S: independent components (source signals)\n",
    "    \"\"\"\n",
    "    # Get HEOG and VEOG\n",
    "    channels = []\n",
    "    for ch in ['heog', 'veog']:\n",
    "        if ch in trial_data.columns:\n",
    "            processed = process_eog_signal(trial_data[ch].values, sample_rate=sample_rate)\n",
    "            channels.append(processed)\n",
    "    \n",
    "    if len(channels) < 2:\n",
    "        return None, None\n",
    "    \n",
    "    # Stack channels: shape (n_samples, n_channels)\n",
    "    X = np.column_stack(channels)\n",
    "    \n",
    "    # Apply ICA\n",
    "    ica = FastICA(n_components=n_components, random_state=42, max_iter=1000)\n",
    "    S = ica.fit_transform(X)\n",
    "    \n",
    "    return ica, S\n",
    "\n",
    "\n",
    "def plot_ica_comparison(trial_data, sample_rate=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    Compare original channels with ICA-separated components.\n",
    "    \"\"\"\n",
    "    ica, S = apply_ica_to_signals(trial_data, sample_rate=sample_rate)\n",
    "    \n",
    "    if S is None:\n",
    "        print(\"ICA failed - need at least 2 channels\")\n",
    "        return\n",
    "    \n",
    "    time = np.arange(len(trial_data)) / sample_rate\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "    \n",
    "    # Original channels\n",
    "    axes[0, 0].plot(time, process_eog_signal(trial_data['heog'].values), 'b-', linewidth=0.8)\n",
    "    axes[0, 0].set_title('Original HEOG')\n",
    "    axes[0, 0].set_xlabel('Time (s)')\n",
    "    axes[0, 0].set_ylabel('Amplitude')\n",
    "    \n",
    "    axes[0, 1].plot(time, process_eog_signal(trial_data['veog'].values), 'r-', linewidth=0.8)\n",
    "    axes[0, 1].set_title('Original VEOG')\n",
    "    axes[0, 1].set_xlabel('Time (s)')\n",
    "    axes[0, 1].set_ylabel('Amplitude')\n",
    "    \n",
    "    # ICA components\n",
    "    axes[1, 0].plot(time, S[:, 0], 'g-', linewidth=0.8)\n",
    "    axes[1, 0].set_title('ICA Component 1')\n",
    "    axes[1, 0].set_xlabel('Time (s)')\n",
    "    axes[1, 0].set_ylabel('Amplitude')\n",
    "    \n",
    "    axes[1, 1].plot(time, S[:, 1], 'm-', linewidth=0.8)\n",
    "    axes[1, 1].set_title('ICA Component 2')\n",
    "    axes[1, 1].set_xlabel('Time (s)')\n",
    "    axes[1, 1].set_ylabel('Amplitude')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print mixing matrix\n",
    "    print(\"\\nICA Mixing Matrix (how components combine to form original signals):\")\n",
    "    print(f\"  HEOG = {ica.mixing_[0, 0]:.3f} * IC1 + {ica.mixing_[0, 1]:.3f} * IC2\")\n",
    "    print(f\"  VEOG = {ica.mixing_[1, 0]:.3f} * IC1 + {ica.mixing_[1, 1]:.3f} * IC2\")\n",
    "\n",
    "# Apply ICA to a trial with blinks\n",
    "if all_data:\n",
    "    # Try blink trials first, then any available trial\n",
    "    for gaze in ['blink', 'double_blink', 'left', 'right', 'center']:\n",
    "        if gaze in all_data and all_data[gaze]:\n",
    "            print(f\"ICA analysis on '{gaze}' trial:\")\n",
    "            plot_ica_comparison(all_data[gaze][0])\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 7 Response\n",
    "\n",
    "**How much variance is explained by each principal component? What do the first two principal components represent in terms of eye movements?**\n",
    "\n",
    "*Your observations:*\n",
    "\n",
    "- PC1 explains ___% of variance and seems to represent: ___\n",
    "- PC2 explains ___% of variance and seems to represent: ___\n",
    "- Total variance explained by first 2 PCs: ___\n",
    "\n",
    "---\n",
    "\n",
    "## Question 8 Response\n",
    "\n",
    "**How do the ICA-separated components differ from the original HEOG and VEOG channels? Can you identify components that correspond to horizontal movement, vertical movement, and blinks?**\n",
    "\n",
    "*Your observations:*\n",
    "\n",
    "- ICA Component 1 appears to capture: ___\n",
    "- ICA Component 2 appears to capture: ___\n",
    "- The mixing matrix suggests: ___\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Classification with SVM\n",
    "\n",
    "Train and evaluate Support Vector Machine classifiers for gaze direction classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_classification_data(feature_df, gaze_classes=None):\n",
    "    \"\"\"\n",
    "    Prepare feature matrix and labels for classification.\n",
    "    \n",
    "    Returns:\n",
    "        X: feature matrix (scaled)\n",
    "        y: labels (encoded)\n",
    "        feature_names: list of feature names\n",
    "        label_encoder: fitted LabelEncoder\n",
    "        scaler: fitted StandardScaler\n",
    "    \"\"\"\n",
    "    # Filter to specified classes\n",
    "    if gaze_classes is not None:\n",
    "        df = feature_df[feature_df['gaze'].isin(gaze_classes)].copy()\n",
    "    else:\n",
    "        df = feature_df.copy()\n",
    "    \n",
    "    # Get feature columns\n",
    "    exclude_cols = ['gaze', 'trial', 'participant']\n",
    "    feature_cols = [c for c in df.columns if c not in exclude_cols]\n",
    "    \n",
    "    X = df[feature_cols].values\n",
    "    X = np.nan_to_num(X, nan=0)  # Handle missing values\n",
    "    \n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(df['gaze'])\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return X_scaled, y, feature_cols, label_encoder, scaler\n",
    "\n",
    "\n",
    "def train_and_evaluate_svm(X, y, label_encoder, kernel='rbf', test_size=0.3):\n",
    "    \"\"\"\n",
    "    Train an SVM classifier and evaluate performance.\n",
    "    \n",
    "    Args:\n",
    "        X: scaled feature matrix\n",
    "        y: encoded labels\n",
    "        label_encoder: for decoding labels\n",
    "        kernel: 'linear' or 'rbf'\n",
    "        test_size: fraction of data for testing\n",
    "        \n",
    "    Returns:\n",
    "        model: trained SVM\n",
    "        results: dict with accuracy, confusion matrix, etc.\n",
    "    \"\"\"\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Train SVM\n",
    "    if kernel == 'linear':\n",
    "        model = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "    else:  # rbf\n",
    "        model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred,\n",
    "                                    target_names=label_encoder.classes_,\n",
    "                                    output_dict=True)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    \n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': report,\n",
    "        'y_test': y_test,\n",
    "        'y_pred': y_pred\n",
    "    }\n",
    "    \n",
    "    return model, results\n",
    "\n",
    "print(\"Classification functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names, title='Confusion Matrix'):\n",
    "    \"\"\"\n",
    "    Plot a confusion matrix with labels.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    \n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=class_names,\n",
    "           yticklabels=class_names,\n",
    "           title=title,\n",
    "           ylabel='True Label',\n",
    "           xlabel='Predicted Label')\n",
    "    \n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    \n",
    "    # Add text annotations\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compare_svm_kernels(feature_df, gaze_classes=None):\n",
    "    \"\"\"\n",
    "    Train and compare Linear vs RBF SVM.\n",
    "    \"\"\"\n",
    "    X, y, feature_names, label_encoder, scaler = prepare_classification_data(\n",
    "        feature_df, gaze_classes\n",
    "    )\n",
    "    \n",
    "    print(f\"Dataset: {len(y)} samples, {len(np.unique(y))} classes\")\n",
    "    print(f\"Features: {len(feature_names)}\")\n",
    "    print(f\"Classes: {label_encoder.classes_}\\n\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for kernel in ['linear', 'rbf']:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"  SVM with {kernel.upper()} kernel\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        model, res = train_and_evaluate_svm(X, y, label_encoder, kernel=kernel)\n",
    "        results[kernel] = res\n",
    "        \n",
    "        print(f\"\\n  Test Accuracy: {res['accuracy']*100:.2f}%\")\n",
    "        print(f\"  Cross-validation: {res['cv_mean']*100:.2f}% (+/- {res['cv_std']*100:.2f}%)\")\n",
    "        \n",
    "        print(\"\\n  Classification Report:\")\n",
    "        for cls in label_encoder.classes_:\n",
    "            metrics = res['classification_report'][cls]\n",
    "            print(f\"    {cls:15s} precision={metrics['precision']:.2f} \"\n",
    "                  f\"recall={metrics['recall']:.2f} f1={metrics['f1-score']:.2f}\")\n",
    "        \n",
    "        plot_confusion_matrix(res['confusion_matrix'], label_encoder.classes_,\n",
    "                              title=f'Confusion Matrix - {kernel.upper()} SVM')\n",
    "    \n",
    "    # Summary comparison\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"  SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"  Linear SVM: {results['linear']['accuracy']*100:.2f}% \"\n",
    "          f\"(CV: {results['linear']['cv_mean']*100:.2f}%)\")\n",
    "    print(f\"  RBF SVM:    {results['rbf']['accuracy']*100:.2f}% \"\n",
    "          f\"(CV: {results['rbf']['cv_mean']*100:.2f}%)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Train and evaluate classifiers\n",
    "if all_data and 'feature_df' in dir() and len(feature_df) > 10:\n",
    "    classification_results = compare_svm_kernels(feature_df)\n",
    "else:\n",
    "    print(\"Not enough data for classification. Need at least 10 samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 9 Response\n",
    "\n",
    "**Compare the classification accuracy of Linear SVM vs. RBF SVM. Which performs better on your data, and why might this be?**\n",
    "\n",
    "*Your observations:*\n",
    "\n",
    "- Linear SVM accuracy: ___%\n",
    "- RBF SVM accuracy: ___%\n",
    "- The better performing kernel is: ___\n",
    "- This might be because: ___\n",
    "\n",
    "---\n",
    "\n",
    "## Question 10 Response\n",
    "\n",
    "**Examine the confusion matrix. Which gaze directions are most often confused with each other? Does this make sense given the electrode placement and expected signals?**\n",
    "\n",
    "*Your observations:*\n",
    "\n",
    "- Most commonly confused classes: ___ and ___\n",
    "- This makes sense because: ___\n",
    "- Classes that are well-separated: ___\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of Reducing Gaze Classes\n",
    "\n",
    "Let's see how classification accuracy changes with fewer classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reduced_classes(feature_df):\n",
    "    \"\"\"\n",
    "    Test classification with different subsets of gaze classes.\n",
    "    \"\"\"\n",
    "    class_subsets = [\n",
    "        ['left', 'right'],                          # Horizontal only\n",
    "        ['up', 'down'],                             # Vertical only\n",
    "        ['left', 'right', 'center'],                # Horizontal + center\n",
    "        ['left', 'right', 'up', 'down'],            # Cardinal directions\n",
    "        ['left', 'right', 'up', 'down', 'center'],  # All directions\n",
    "        ['left', 'right', 'up', 'down', 'center', 'blink'],  # + blink\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for classes in class_subsets:\n",
    "        # Filter to classes that exist in our data\n",
    "        available_classes = [c for c in classes if c in feature_df['gaze'].unique()]\n",
    "        \n",
    "        if len(available_classes) < 2:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            X, y, _, label_encoder, _ = prepare_classification_data(\n",
    "                feature_df, available_classes\n",
    "            )\n",
    "            \n",
    "            if len(np.unique(y)) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Quick cross-validation with RBF SVM\n",
    "            model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "            cv_scores = cross_val_score(model, X, y, cv=min(5, len(y)//2), scoring='accuracy')\n",
    "            \n",
    "            results.append({\n",
    "                'classes': available_classes,\n",
    "                'n_classes': len(available_classes),\n",
    "                'n_samples': len(y),\n",
    "                'accuracy': cv_scores.mean(),\n",
    "                'std': cv_scores.std()\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error with classes {available_classes}: {e}\")\n",
    "    \n",
    "    # Display results\n",
    "    if results:\n",
    "        print(\"\\nClassification Accuracy by Number of Classes:\")\n",
    "        print(\"-\" * 70)\n",
    "        for r in results:\n",
    "            class_str = ', '.join(r['classes'])\n",
    "            print(f\"  {r['n_classes']} classes ({r['n_samples']:3d} samples): \"\n",
    "                  f\"{r['accuracy']*100:.1f}% +/- {r['std']*100:.1f}%\")\n",
    "            print(f\"    Classes: {class_str}\")\n",
    "        \n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        x = [r['n_classes'] for r in results]\n",
    "        y = [r['accuracy'] * 100 for r in results]\n",
    "        yerr = [r['std'] * 100 for r in results]\n",
    "        \n",
    "        ax.errorbar(x, y, yerr=yerr, fmt='o-', capsize=5, markersize=10)\n",
    "        ax.set_xlabel('Number of Gaze Classes')\n",
    "        ax.set_ylabel('Classification Accuracy (%)')\n",
    "        ax.set_title('Classification Accuracy vs. Number of Classes')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_ylim(0, 105)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "if all_data and 'feature_df' in dir() and len(feature_df) > 10:\n",
    "    reduced_results = test_reduced_classes(feature_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 11 Response\n",
    "\n",
    "**How does reducing the number of gaze classes affect classification accuracy?**\n",
    "\n",
    "*Your observations:*\n",
    "\n",
    "- 2-class (left/right) accuracy: ___%\n",
    "- 3-class accuracy: ___%\n",
    "- 5-class accuracy: ___%\n",
    "- The trend shows: ___\n",
    "- For a practical interface, I would recommend ___ classes because: ___\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Summary and Conclusions\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "Summarize your main findings from this analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics\n",
    "if all_data and 'feature_df' in dir() and 'classification_results' in dir():\n",
    "    print(\"=\"*60)\n",
    "    print(\"  LAB 2 ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Data summary\n",
    "    print(\"\\n📊 DATA COLLECTED:\")\n",
    "    print(f\"   Total trials: {len(feature_df)}\")\n",
    "    print(f\"   Gaze classes: {list(feature_df['gaze'].unique())}\")\n",
    "    if 'participant' in feature_df.columns:\n",
    "        print(f\"   Participants: {list(feature_df['participant'].unique())}\")\n",
    "    \n",
    "    # Feature summary\n",
    "    print(\"\\n📈 FEATURES:\")\n",
    "    exclude_cols = ['gaze', 'trial', 'participant']\n",
    "    n_features = len([c for c in feature_df.columns if c not in exclude_cols])\n",
    "    print(f\"   Number of features: {n_features}\")\n",
    "    \n",
    "    # PCA summary\n",
    "    if 'pca' in dir():\n",
    "        print(\"\\n🔄 DIMENSIONALITY REDUCTION (PCA):\")\n",
    "        print(f\"   PC1 variance: {pca.explained_variance_ratio_[0]*100:.1f}%\")\n",
    "        print(f\"   PC2 variance: {pca.explained_variance_ratio_[1]*100:.1f}%\")\n",
    "    \n",
    "    # Classification summary\n",
    "    print(\"\\n🎯 CLASSIFICATION RESULTS:\")\n",
    "    print(f\"   Linear SVM: {classification_results['linear']['accuracy']*100:.1f}%\")\n",
    "    print(f\"   RBF SVM: {classification_results['rbf']['accuracy']*100:.1f}%\")\n",
    "    \n",
    "    best_kernel = 'rbf' if classification_results['rbf']['accuracy'] > classification_results['linear']['accuracy'] else 'linear'\n",
    "    print(f\"   Best kernel: {best_kernel.upper()}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Discussion Questions\n",
    "\n",
    "Answer these final questions for your lab report:\n",
    "\n",
    "### Question 12\n",
    "**What are the main differences between EOG and EMG signals in terms of frequency content, amplitude, and signal characteristics?**\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "---\n",
    "\n",
    "### Question 13\n",
    "**Why might EOG-based gaze tracking be preferred over camera-based eye tracking in certain applications? What are the limitations of EOG?**\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "---\n",
    "\n",
    "### Question 14\n",
    "**If you were designing a practical EOG-based interface (e.g., for a wheelchair or computer control), which gaze commands would you include and why? How would you handle false positives?**\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "---\n",
    "\n",
    "### Question 15\n",
    "**How could the blink signal be used as an additional control input rather than just an artifact to be removed?**\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Save your processed data and results for the lab report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature dataframe\n",
    "if 'feature_df' in dir():\n",
    "    output_path = DATA_DIR / 'features_extracted.csv'\n",
    "    feature_df.to_csv(output_path, index=False)\n",
    "    print(f\"Features saved to: {output_path}\")\n",
    "\n",
    "# Save classification results\n",
    "if 'classification_results' in dir():\n",
    "    results_summary = {\n",
    "        'linear_accuracy': classification_results['linear']['accuracy'],\n",
    "        'linear_cv_mean': classification_results['linear']['cv_mean'],\n",
    "        'rbf_accuracy': classification_results['rbf']['accuracy'],\n",
    "        'rbf_cv_mean': classification_results['rbf']['cv_mean'],\n",
    "    }\n",
    "    results_df = pd.DataFrame([results_summary])\n",
    "    results_path = DATA_DIR / 'classification_results.csv'\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    print(f\"Classification results saved to: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Appendix: Synthetic Data for Testing\n",
    "\n",
    "If you don't have real data yet, you can generate synthetic EOG data to test the analysis pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_eog(gaze_direction, duration_s=3.0, sample_rate=250):\n",
    "    \"\"\"\n",
    "    Generate synthetic EOG data for testing.\n",
    "    \n",
    "    Args:\n",
    "        gaze_direction: 'center', 'left', 'right', 'up', 'down', 'blink'\n",
    "        duration_s: duration in seconds\n",
    "        sample_rate: samples per second\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with heog, veog columns\n",
    "    \"\"\"\n",
    "    n_samples = int(duration_s * sample_rate)\n",
    "    time = np.arange(n_samples) / sample_rate\n",
    "    \n",
    "    # Base noise\n",
    "    noise_level = 10  # μV\n",
    "    heog = np.random.randn(n_samples) * noise_level\n",
    "    veog = np.random.randn(n_samples) * noise_level\n",
    "    \n",
    "    # Add gaze-specific signals\n",
    "    amplitude = 100  # μV for full gaze shift\n",
    "    \n",
    "    if gaze_direction == 'left':\n",
    "        heog += -amplitude + np.random.randn() * 20\n",
    "    elif gaze_direction == 'right':\n",
    "        heog += amplitude + np.random.randn() * 20\n",
    "    elif gaze_direction == 'up':\n",
    "        veog += amplitude + np.random.randn() * 20\n",
    "    elif gaze_direction == 'down':\n",
    "        veog += -amplitude + np.random.randn() * 20\n",
    "    elif gaze_direction == 'blink':\n",
    "        # Add blink artifact at random position\n",
    "        blink_pos = np.random.randint(n_samples // 4, 3 * n_samples // 4)\n",
    "        blink_width = int(0.15 * sample_rate)  # 150ms blink\n",
    "        blink_shape = np.exp(-((np.arange(blink_width) - blink_width//2)**2) / (2 * (blink_width/4)**2))\n",
    "        veog[blink_pos:blink_pos+blink_width] += 300 * blink_shape\n",
    "    elif gaze_direction == 'double_blink':\n",
    "        # Add two blink artifacts\n",
    "        for offset in [0.3, 0.6]:\n",
    "            blink_pos = int(offset * n_samples)\n",
    "            blink_width = int(0.15 * sample_rate)\n",
    "            blink_shape = np.exp(-((np.arange(blink_width) - blink_width//2)**2) / (2 * (blink_width/4)**2))\n",
    "            if blink_pos + blink_width < n_samples:\n",
    "                veog[blink_pos:blink_pos+blink_width] += 300 * blink_shape\n",
    "    # center: just noise\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'timestamp': time,\n",
    "        'heog': heog,\n",
    "        'veog': veog\n",
    "    })\n",
    "\n",
    "\n",
    "def generate_synthetic_dataset(trials_per_class=15, gaze_classes=GAZE_CLASSES):\n",
    "    \"\"\"\n",
    "    Generate a complete synthetic dataset.\n",
    "    \"\"\"\n",
    "    data = {gaze: [] for gaze in gaze_classes}\n",
    "    \n",
    "    for gaze in gaze_classes:\n",
    "        for trial in range(trials_per_class):\n",
    "            df = generate_synthetic_eog(gaze)\n",
    "            df['participant'] = 'synthetic'\n",
    "            df['trial'] = trial\n",
    "            df['gaze'] = gaze\n",
    "            data[gaze].append(df)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate synthetic data if no real data available\n",
    "if all_data is None or all([len(v) == 0 for v in all_data.values()]):\n",
    "    print(\"Generating synthetic EOG data for demonstration...\")\n",
    "    all_data = generate_synthetic_dataset(trials_per_class=15)\n",
    "    print(\"Synthetic data generated!\")\n",
    "    \n",
    "    # Extract features from synthetic data\n",
    "    feature_df = extract_all_features(all_data)\n",
    "    print(f\"Extracted features from {len(feature_df)} synthetic trials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*End of Lab 2 Analysis Notebook*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
